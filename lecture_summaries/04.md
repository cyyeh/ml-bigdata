# ML with Large Datasets: Data Cleaning

###### tags: `ml`

slides: https://drive.google.com/file/d/1jU7EBsWbaO_p8ag8viP5m74rFTiqwdIE/view

## Outline

![](https://i.imgur.com/U0i2Kss.png)

## Lecture Summaries

- data cleaning
    - process of fixing errors and inconsistencies in data
    - subject of research for over 50 years
    - data preparation takes most of the time
    - important to several disciplines and it's approached by each a bit differently
        - **statistics view**
        ![](https://i.imgur.com/6yk7zS2.png)
        - **database view**
        ![](https://i.imgur.com/NepKefw.png)
        - **domain expert view**
        ![](https://i.imgur.com/zC1hCjF.png)
        - **data scientist's view**
        ![](https://i.imgur.com/x9oZ4Ui.png)
- we can end up with data quality problems for a number of reasons
    - (source) data is dirty on its own
    - transformations corrupt data(complexity of software pipelines)
    - clean datasets screwed up by integration(i.e., combining them)
    - "rare" errors can become frequent after transformation/integration
    - clean datasets can suffer "bit rot": data loses value/accuracy over time
- what are some of the things we need to watch out for?
![](https://i.imgur.com/a41m8Ou.png)
- the data quality continuum
![](https://i.imgur.com/sF6ifgr.png)
![](https://i.imgur.com/9W0i797.png)
![](https://i.imgur.com/tyCnNNF.png)
![](https://i.imgur.com/zmxFMfi.png)
![](https://i.imgur.com/3RYmNMx.png)
![](https://i.imgur.com/DBnA71f.png)
![](https://i.imgur.com/27ogHrz.png)
![](https://i.imgur.com/uAPHi06.png)
![](https://i.imgur.com/VYc6kdH.png)
![](https://i.imgur.com/KNfQZjC.png)
![](https://i.imgur.com/hr0uIkS.png)
- ways to reduce possible data problems
    - macroscopically
    ![](https://i.imgur.com/BnDtHIG.png)
    - data quality constraints
    ![](https://i.imgur.com/o77KmRf.png)
    - data quality metrics
        - to measure data quality constraints
        ![](https://i.imgur.com/1ceNRdc.png)
- solving data integration problems
    ![](https://i.imgur.com/FucbYlw.png)
    - duplicate record detection (dedup)
        - example: entity resolution(see [hw1](https://github.com/cyyeh/ml-bigdata/tree/master/assignments/hw1)), problem of identifying and linking/grouping different manifestations of the same real world object