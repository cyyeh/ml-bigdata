# ML with Large Datasets: Distributed Computing, MapReduce

###### tags: `ml`

slides: https://drive.google.com/file/d/1PD9ySy1XSbm8gC0aDX59P0cOO_mwx8Eu/view

## Outline

![](https://i.imgur.com/0GsGQ3p.png)

## Lecture Summaries

- data are generated from a lot of sources
    - IoT
    - user activities on Internet
    - machine log files
    - etc.
- data analysis tools
    - traditional(working well on a single machine)
        - Python
        - R
        - shell commands(grep, awk, sed)
    - modern solution
        - cloud computing
            - AWS
            - GCP
            - Azure
- brief history of big data processing
    - all processors share memory(1990s)
    - lots of consumer-grade computer connected
        - we need more complex software to be able to run on lots of smaller/cheaper machines
        - problems
            - hardwar failures are common
            - network latency higher than shared memory
            - uneven performance
- data parallelism
    - shared memory
        - split data
        - workers/threads independently operate on the data shards in parallel
        - combine when done(if necessary)
        - **Scala's Parallel Collections is a collections abstraction over shared memory data-parallel execution**
    - distributed
        - split data over several nodes
        - nodes independently operate on the data shards in parallel
        - combine when done(if necessary)
        - **we need to worry about network latency between workers**
        - **we can keep collections abstraction over distributed data-parallel execution**
            - watch out for non-associative reduction operations!: `.reduce(_-_)`
- important latency numbers
    ![](https://i.imgur.com/KqnPAwq.png)
- Apache Spark
    - Spark implements a distributed data parallel model called **Resilient Distributed Datasets(RDDs)**
    - why Spark(compared to Hadoop/MapReduce)
        - between each map and reduce step, in order to recover from potential failures, Hadoop/MapReduce shuffles its data and write intermediate data to disk
        ![](https://i.imgur.com/zxWU89H.png)
        - Spark retains fault-tolerance, but using different strategy for handling latency
        ![](https://i.imgur.com/eziJUUh.png)
        ![](https://i.imgur.com/Up2UyJw.png)
