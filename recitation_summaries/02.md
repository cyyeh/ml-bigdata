# ML with Large Datasets: Spark Transformations and Actions

###### tags: `ml`

- slides: https://drive.google.com/file/d/1SDXaALpPXAi6CMNYcupEloc-FvYJxmm9/view
- lab2 notebook: https://github.com/cyyeh/ml-bigdata/blob/master/labs/Recitation2.ipynb

## Recitation Summaries

- interesting Pair RDD(RDD containing tuples(also called pairs)) operations
    - transformations
        - `groupByKey`
            - When called on a dataset of ``(K, V)`` pairs, `groupByKey` returns a dataset of `(K, Iterable<V>)` pairs.
        - `reduceByKey`
            - `reduceByKey` can be thought of as a combination of `groupByKey` and `reduce`-ing on all the values per key. Itâ€™s more efficient though than using each separately.
            - by reducing the dataset first, the amount of data sent over the network during the shuffle is greatly reduced
        - `mapValues`
            - can be thought of as a doing: `rdd.map { lambda p: (p[0], func(p[1]))}`
            - it simply applies a function to only the values in a Pair RDD
        - `keys`
        - `join`
        - `leftOuterJoin`
        - `rightOuterJoin`
    - action
        - `countByKey`
            - counts the number of elements per key in a Pair RDD, returning a hashmap mapping from keys to counts.